{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCaViqr17dhd"
      },
      "outputs": [],
      "source": [
        "\n",
        "#IMPORTING NECESSARY LIBRARIES\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING THE YOLO MODEL\n",
        "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")"
      ],
      "metadata": {
        "id": "S_OBNwWb7pQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING THE FILE WITH CLASSES\n",
        "with open(\"coco128.yaml\", \"r\") as f:\n",
        "\n",
        "    classes = f.read().strip().split(\"\\n\")\n"
      ],
      "metadata": {
        "id": "7fBT9AGp7qBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENING THE VIDEO FILE AND READING THE FILE FRAME BY FRAME\n",
        "video_capture = cv2.VideoCapture('trafficjam.mp4')\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "JQk8Zp_q7seD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # PERFORMING OBJECT DETECTION\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False) #CONVERTS A FRAME INTO A BLOB FOR COMPATIBILTY WITH DNN\n",
        "    net.setInput(blob) #PREPROCESSES THESE FRAMES OR BLOBS\n",
        "    outs = net.forward(net.getUnconnectedOutLayersNames()) #PREPROCESSES THE BLOBS AND STORED THE PROCESSED FRAMES IN THE OUTS VARIABLE"
      ],
      "metadata": {
        "id": "xKMtUlU87voa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_threshold = 0.3 #CONFIDENCE THRESHOLD (THE CONTOURS BELOW THIS THRESHOLD WILL BE IGNORED)\n",
        "    nms_threshold = 0.5\n",
        "    boxes = []\n",
        "    for out in outs: #ITERATES OVER EACH OUTPUT FRAME\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > conf_threshold:\n",
        "                center_x, center_y, width, height = (detection[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]))\n",
        "                x, y = int(center_x - width / 2), int(center_y - height / 2)\n",
        "                boxes.append([x, y, int(width), int(height)])"
      ],
      "metadata": {
        "id": "tw5YjI2v7yuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # DRAWING BOUNDING BOXES ON THE VIDEO FRAME\n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)"
      ],
      "metadata": {
        "id": "Wz-uT1BR74BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DEFINING THE CINGESTION DENSITY AND IT'S THRESHOLD TO CLASSIFY THE ROAD IN THE FOOTAGE AS CONGESTED OR NOT CONGESTED\n",
        "    crowd_density = len(boxes) #DENSITY IS EQUAL TO THE NUMBER OF BOXES PLOTTED OR THE NUMBER PF CARS DETECTED ON THE ROAD\n",
        "    congestion_threshold = 40  #THRESHOLD SET TO 40 BOUNDING BOXES .I.E. 40 DETECTED CARS ON A ROAD"
      ],
      "metadata": {
        "id": "e-u2I3SB76Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SETTING A CONDITION TO CLASSIFY THE ROAD IN THE VIDEO AS CONGESTED OR NOT CONGESTED\n",
        "if crowd_density > congestion_threshold:\n",
        "        congestion_status = \"Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "else:\n",
        "        congestion_status = \"Not Congested\"\n",
        "        frame = cv2.putText(frame, f\"Congestion: {congestion_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n"
      ],
      "metadata": {
        "id": "cacPzKFn79X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #DISPLAYING THE FINAL OUTPUT FRAME\n",
        "    cv2.imshow(\"Object Detection\", frame)\n",
        "\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break"
      ],
      "metadata": {
        "id": "V9t_KB_D9l2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#SENDING A BROADCAST MESSAGE USING WHATSAPP TO USERS IF THE ROAD IS CONGESTED USING PYWHATKIT LIBRARY\n",
        "import pywhatkit\n",
        "lst=['+91----------','+91----------']\n",
        "for i in lst:\n",
        "     if congestion_status == 'Congested':\n",
        "        pywhatkit.sendwhatmsg_instantly(i,\"The road:XYZ is congested, if you are planning to travel through this route, you are advised to take an alternate path to avoid congestion\",4,True,4)"
      ],
      "metadata": {
        "id": "uj1txVZh9tH1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}